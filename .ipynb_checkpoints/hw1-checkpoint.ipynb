{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6d4318cfcf5ab38330ce9a2252c5604",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src='https://hammondm.github.io/hltlogo1.png' style=\"float:right\">\n",
    "Linguistics 531<br>\n",
    "Fall 2025<br>\n",
    "Jackson\n",
    "\n",
    "## Things to remember about any homework assignment:\n",
    "\n",
    "1. For this assignment, you will edit this jupyter notebook and turn it in. Do not turn in pdf files or separate `.py` files.\n",
    "1. Late work is not accepted, unless you have one of the excusable circumstances outlined in the syllabus (you or someone you need to care for are ill, you have a personal or family emergency, etc).\n",
    "1. Given the way I grade, you should try to answer *every* question, even if you don't like your answer or have to guess.\n",
    "1. You may *not* use `python` modules that we have not already used in class. (For grading, it needs to be able to run on my machine, and the way to do that is to limit yourself to the modules we've discussed and that are loaded into the Notebook.)\n",
    "1. **Don't use editors *other* than Jupyter Notebook** to work on and submit your assignment, since they will mangle the autograding features: Google Colab, or even just editing the `.ipynb` file as a plain text file. Diagnosing and fixing that kind of problem takes a lot of my time, and that means less of my time to offer constructive feedback to you and to other students.\n",
    "1. You may certainly talk to your classmates about the assignment, but everybody must turn in *their own* work. It is not acceptable to turn in work that is essentially the same as the work of classmates, or the work of someone on Stack Overflow, or the work of a generative AI model. Using someone else's code and simply changing variable or object names is *not* doing your own work.\n",
    "1. All code must run. It doesn't have to be perfect, it may not do all that you want it to do, but it must run without error. Code that runs with errors will get no credit from the autograder.\n",
    "1. Code must run in reasonable time. Assume that if it takes more than *5 minutes* to run (on your machine), that's too long.\n",
    "1. Make sure to select `restart, run all cells` from the `kernel` menu when you're done and before you turn this in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my name: *\\<FILL IN HERE\\>*\n",
    "\n",
    "people I talked to about the assignment: *\\<FILL IN HERE\\>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7a6fc2136d1f3fa13118c68ef42b14d",
     "grade": false,
     "grade_id": "q1q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework #1*\n",
    "\n",
    "**This is due Tuesday, October 21, 2025 at noon (Arizona time).**\n",
    "\n",
    "This assignment deals with the `NewB` corpus. We'll be using this is many of our later homeworks, as well. You should download it from [here](https://github.com/JerryWei03/NewB). The contents and structure of the corpus are described in [this article](https://arxiv.org/abs/2006.03051):\n",
    "\n",
    "<p style=\"margin-left: 2em; text-indent: -2em;\">\n",
    "  Wei, Jerry. 2006/2020. NewB: 200,000+ Sentences for Political Bias Detection. <a href=\"https://dblp.uni-trier.de/db/journals/corr/corr2006.html#abs-2006-03051\">CoRR abs/2006.03051</a> <a href=\"https://doi.org/10.48550/arXiv.2006.03051\">https://doi.org/10.48550/arXiv.2006.03051</a>\n",
    "</p>\n",
    "\n",
    "\n",
    "## Useful terminology\n",
    "\n",
    "Before you start, here's a bit of background to get you headed in the right direction. In general contexts, the terms *file* and *document* can often be used interchangeably. However, in the following explanation, we follow the readings and the lecture in using them with these formal definitions:\n",
    "\n",
    "*file* --> a unit on our computer in which data is stored\n",
    "\n",
    "*document* --> an abstract unit of text in our corpus that we will be searching over, which we define based on the nature of our corpus and the kinds of results that we think will be most useful to users; one or more documents will be the units that we want to return to users as a result of a search query; the set of all documents is called the collection, and each document is described by a unique document ID.\n",
    "\n",
    "One of the tasks that we need to do to prepare for searching a collection is to separate the documents in the collection from [metadata about those documents](https://bernardmarr.com/what-is-metadata-a-simple-explanation-of-what-everyone-should-know/#:~:text=Quite%20simply%3A%20metadata%20is%20data,web%20pages%2C%20content%20or%20spreadsheets.). In the video lectures, the documents that comprise our collection are blog posts, and the metadata for each post includes an author identifier, the author's age and gender, the author's interests, and the author's zodiacal sign. The posts for a single author are arranged in a single file. The metadata about those documents is found in the file names, and one of the first tasks that Mike does in the lectures is to write a function to read in the documents (ie, each post) and link each document with its metadata.\n",
    "\n",
    "For this question on the homework, you need to think about these same issues for the NewB corpus. What are the documents that comprise this collection, that we will be searching over, and that we will be returning as the result of a query? What metadata do we have about each document? How is all of this stored in a file that we will read in, so that we can build an index? To answer this question, you may need to read the paper that describes the NewB corpus, which you can find in the Readings module. In this homework, you will see which of the files from the corpus we will be working with. Look at the docstrings for the two functions you need to build, and see what their arguments and their output will be like. Read the assert statements to see what tests will be performed on the output, and that will also give you clues about what data structure you should use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58880837bd0066f9411d37effc40202d",
     "grade": false,
     "grade_id": "cell-85e7bb5f0c446cb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Mechanical considerations for auto-grading\n",
    "\n",
    "**Please read this carefully to make my autograding life easier (and your own notebook more likely to be graded correctly):**\n",
    "\n",
    "In order for me to develop this assignment, and in order for me to **grade** your submission for this assignment, I need to be working with the right file that we load our corpus from. On my machine, that file has this path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e62c1b799988ddf52f20674372e75424",
     "grade": false,
     "grade_id": "cell-b7e8e00e5c53b643",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DON'T EDIT THIS CELL, ENTER YOUR PATH IN THE NEXT ONE BELOW! ###\n",
    "\n",
    "# Path on my own machine, needed for GRADING\n",
    "newbfile = '/home/ejackson1/Downloads/linguistics/NewB/train_orig.txt'\n",
    "\n",
    "### DON'T EDIT THIS CELL, ENTER YOUR PATH IN THE NEXT ONE BELOW! ###\n",
    "#  If you change *this* cell, the autograder is likely to break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2238ac222536353ba9b388dd1a732df8",
     "grade": false,
     "grade_id": "cell-d0e80501da445a0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "However, for **you** to work on your own code, you need to point this notebook to the path for this file on your own machine. *You should enter the path on your own machine in the editable code cell below,* then uncomment that line so the notebook works on your machine. This means that when you restart the kernel for this notebook and run all cells, the code cell below will take precedence in assigning the value of the path to the corpus in `newbfile`, and you can write your code to open that file without problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EDITABLE CELL ###\n",
    "# YOUR path -- uncomment the following line while you work\n",
    "#newbfile = '/path/to/this/file/on/your/machine/train_orig.txt'\n",
    "#  THEN RE-COMMENT IT before you submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HOWEVER, BEFORE YOU SUBMIT this notebook to D2L**, comment out **your** path again. This means that when I restart the kernel for this notebook and run all cells *on my own machine*, `newbfile` will only ever be assigned the path that ***I*** need, and the autograder will grade your notebook properly.\n",
    "\n",
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0753cd6470b558569e63fe8ec6060fc7",
     "grade": false,
     "grade_id": "cell-ada6dcc2d569fd2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**1.** Describe the general logic and contents of the NewB corpus. (ie, you'll need to read the paper describing the corpus (linked above)! What data is in it? Where did it come from? What structure does the data in the corpus have?) (1-2 paragraphs, 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84c221e24415142c789f6cabf1967cac",
     "grade": true,
     "grade_id": "q1a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "244824d3056bcfd853196d0235fc1a8e",
     "grade": false,
     "grade_id": "q2q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.** Describe the file structure. Specifically tell me what you'll have to do to parse those files to produce reasonable data structures for searching. (ie, what parts of the associated files are the \"documents\", and what parts are the metadata? What **is** the metadata in this corpus?) (1-3 paragraphs, 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09832d0ffcdd6d1174930ee7b2d08021",
     "grade": true,
     "grade_id": "q2a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f92ea5f87e9dc62589171a2aad0e67c",
     "grade": false,
     "grade_id": "q3q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.** Fill out the function below to parse the `train_orig.txt` file into lines. We'll feed the `newbfile` object (which stores the path to the `train_orig.txt` file) into this function, and the should return the lines of this file as a list, with trailing newlines removed. **Be sure to read the information that is provided to you [in the docstring](https://realpython.com/how-to-write-docstrings-in-python/) for this and subsequent functions.** We'll be treating each sentence as a separate *document* in our *collection*.\n",
    "\n",
    "There are different ways that you can read a file in Python. For a refresher, you may find [this tutorial](https://realpython.com/read-write-files-python/#reading-and-writing-opened-files) helpful, or you can always check the [official documentation](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files). You can approach the problem here in different ways, but whatever method you use, just be sure you can pass the tests. (2 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dff6e3a1b71399dc7619734c1c28a684",
     "grade": false,
     "grade_id": "q3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getlines(filepath):\n",
    "    \"\"\"\n",
    "    read in a file path and return the lines of text in that file\n",
    "    \n",
    "    args:\n",
    "        filepath (str): path to a text file\n",
    "        \n",
    "    returns:\n",
    "        lines (list[str]): a list of lines (with trailing newlines \\n removed)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af677793c59304e40daf4a7ff2a7688",
     "grade": true,
     "grade_id": "q3t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3a, 1 pt\n",
    "result = getlines(newbfile)\n",
    "assert isinstance(result, list) and all((isinstance(item, str) and item[-1][-1] not in ('\\n', '\\r')) for item in result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a4cd7fe97dcedd388d664771bafc104",
     "grade": true,
     "grade_id": "q3t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3b, 1 pt\n",
    "result = getlines(newbfile)\n",
    "assert len(result) == 253781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e66923b3c211482bb4bf86ab9bbf3db",
     "grade": false,
     "grade_id": "q4q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**4.** Now fill out the function below to **take the output of `getlines()` and parse it into a list of tuples**. Each tuple consists of the publication ID as an integer (in the interval 0 to 10, inclusive) and the sentence as a string. If you're not sure how to process what you read from the file, you can always look at the first part of what you've read in (for instance, using a slice), or you can open the input file in a text editor. (4 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4b4f217dccf24e1c2c7a97140c70700",
     "grade": false,
     "grade_id": "q4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def makeSentences(lines):\n",
    "    \"\"\"\n",
    "    convert a list of lines of text from the NewB corpus into a list of tuples\n",
    "    \n",
    "    args:\n",
    "        lines (str): the list of lines produced by getlines()\n",
    "    \n",
    "    returns:\n",
    "        [(<publication_id>, \"<sentence as a string>\"), ...]\n",
    "        a list of tuples of the form (int, str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e66eb76234c38774b399e55355014a9d",
     "grade": true,
     "grade_id": "q4t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4a, 1pt\n",
    "lines = getlines(newbfile)\n",
    "sentences = makeSentences(lines)\n",
    "assert isinstance(sentences, list) and all((isinstance(item, tuple) and isinstance(item[0],int) and isinstance(item[1],str)) for item in sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4abd27982e8d2c3fbad9b4e3d9f455b",
     "grade": true,
     "grade_id": "q4t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4b, 1pt\n",
    "assert len(sentences) == 253781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e21e3c78d6887555041d3553291c9a7b",
     "grade": true,
     "grade_id": "q4t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4c, 1pt\n",
    "from collections import Counter\n",
    "doc_counts = Counter([id for id, sentence in sentences])\n",
    "assert all([count == 23071 for id, count in doc_counts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0b5e0f58a4535c46821bc9780b877c7",
     "grade": true,
     "grade_id": "q4t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4d, 1pt\n",
    "assert sentences[92294] == (4, 'if they criticize trump the president attacks them')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
