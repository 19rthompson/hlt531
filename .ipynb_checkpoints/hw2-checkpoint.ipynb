{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6d4318cfcf5ab38330ce9a2252c5604",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src='https://hammondm.github.io/hltlogo1.png' style=\"float:right\">\n",
    "Linguistics 531<br>\n",
    "Fall 2025<br>\n",
    "Jackson\n",
    "\n",
    "## Things to remember about any homework assignment:\n",
    "\n",
    "1. For this assignment, you will edit this jupyter notebook and turn it in. Do not turn in pdf files or separate `.py` files.\n",
    "1. Late work is not accepted, unless you have one of the excusable circumstances outlined in the syllabus (you or someone you need to care for are ill, you have a personal or family emergency, etc).\n",
    "1. Given the way I grade, you should try to answer *every* question, even if you don't like your answer or have to guess.\n",
    "1. You may *not* use `python` modules that we have not already used in class. (For grading, it needs to be able to run on my machine, and the way to do that is to limit yourself to the modules we've discussed and that are loaded into the Notebook.)\n",
    "1. **Don't use editors *other* than Jupyter Notebook** to work on and submit your assignment, since they will mangle the autograding features: Google Colab, or even just editing the `.ipynb` file as a plain text file. Diagnosing and fixing that kind of problem takes a lot of my time, and that means less of my time to offer constructive feedback to you and to other students.\n",
    "1. You may certainly talk to your classmates about the assignment, but everybody must turn in *their own* work. It is not acceptable to turn in work that is essentially the same as the work of classmates, or the work of someone on Stack Overflow, or the work of a generative AI model. Using someone else's code and simply changing variable or object names is *not* doing your own work.\n",
    "1. All code must run. It doesn't have to be perfect, it may not do all that you want it to do, but it must run without error. Code that runs with errors will get no credit from the autograder.\n",
    "1. Code must run in reasonable time. Assume that if it takes more than *5 minutes* to run (on your machine), that's too long.\n",
    "1. Make sure to select `restart, run all cells` from the `kernel` menu when you're done and before you turn this in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my name: *\\Riley Thompson\\>*\n",
    "\n",
    "people I talked to about the assignment: *\\<N/A\\>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6be0f0f1620faadb6ee5e176d5779fd9",
     "grade": false,
     "grade_id": "hw2header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework #2\n",
    "\n",
    "**This is due Tuesday, October 28, 2025 at noon (Arizona time).**\n",
    "\n",
    "This assignment continues with the `NewB` corpus (downloadable [here](https://github.com/JerryWei03/NewB)).\n",
    "\n",
    "We first build an incidence-based term index from the `train_orig.txt` file. Remember that we are treating **each sentence as a separate document when building our index**. We are not treating each publication *source*, as indicated by the integer on each line, as a document; instead, that source number will be metadata. We'll make use of that later, when we look at classification of documents.\n",
    "\n",
    "You may adapt any of the code from class for this or use your own, but bear in mind the that aspects of the code from class notebooks are tailored to the *different* file and data structure of the Blogger corpus. You may also use or adapt code from your first assignment. Do *not* stem or remove stop words.\n",
    "\n",
    "Imports and important constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You may use the RE module, if you choose, to perform the text normalization that is required here.\n",
    "# There may be ways to accomplish what you need to do using the Python standard library, so you're\n",
    "#  not required to use RE--but it's available if you choose.\n",
    "import re\n",
    "\n",
    "# You may also use a Counter() for this and future assignments, though you are not required to do so.\n",
    "#  To learn more about Counter() objects, see https://realpython.com/python-counter/\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71527eb8cec0399079098c32aacfbfa0",
     "grade": false,
     "grade_id": "cell-85e7bb5f0c446cb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**As with HW 1, make my autograding life easier (and your own notebook more likely to be graded correctly):**\n",
    "\n",
    "In order for me to develop this assignment, and in order for me to **grade** your submission for this assignment, I need to be working with the right file that we load our corpus from. On my machine, that file has this path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75201c2a13c3f206ad911f88200f439b",
     "grade": false,
     "grade_id": "cell-b7e8e00e5c53b643",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ie, DON'T CHANGE THIS CELL!\n",
    "#  If you change *this* cell, the autograding is likely to break.\n",
    "\n",
    "# Path on my own machine, needed for GRADING\n",
    "newbfile = '/home/ejackson1/Downloads/linguistics/NewB/train_orig.txt'\n",
    "\n",
    "# ie, DON'T CHANGE THIS CELL, CHANGE THE ONE BELOW!\n",
    "#  If you change *this* cell, the autograding is likely to break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "555072d0e133a10b43330329f1af0f3b",
     "grade": false,
     "grade_id": "cell-26968d9281db051c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "However, for **you** to work on your own code, you need to point this notebook to the path for this file on your own machine. *You should enter the path on your own machine in the editable code cell below,* then uncomment that line so the notebook works on your machine. This means that the second code cell will take precedence in assigning the value of the path to the corpus, and you can write your code to open that file without problems.\n",
    "\n",
    "**HOWEVER, BEFORE YOU SUBMIT to D2L** comment out **your** path again. This means that when I run the code on my own machine, it'll have the path that ***I*** need, and it'll grade your notebook properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE'S THE CELL WHERE YOU ENTER THE PATH TO THE CORPUS ON YOUR MACHINE\n",
    "\n",
    "# YOUR path\n",
    "newbfile = '/home/rthompson/arizona/hlt531/NewB/train_orig.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abda41dd9d38e5ff11b7f14ffffbb633",
     "grade": false,
     "grade_id": "q1q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.** Flesh out the two functions below. One function extracts each sentence from the document and parses off the integer that represents the publication source. For each sentence, we create an \"incidence list\" which is the set of words in that document (as described in the docstring below). (6 points total)\n",
    "\n",
    "The data in the NewB corpus has supposedly already been normalized; things like apostrophes and punctuation have mostly been removed, and all text should have been made lower case. Percent signs have been left on numbers that represent percent. However, it looks like there may be some issues with the normalization method, since some characters besides just lower-case ASCII remain in the document. These include left and right curly braces { }, some back-ticks \\`, and even stranger things. So, in order for us all to be working on the same data and getting the same answers, you're going to also create a normalization and tokenization function that will institute a standard method of preprocessing our text\n",
    "\n",
    "**Before working on `makeDocuments()`, make sure your tokenization function works!**\n",
    "\n",
    "Your `makeDocuments()` function won't be able to pass its tests if your `normalize_tokenize()` function isn't doing what it needs to do. There will be some unscored tests for that tokenization function below this cell, before the \"real\" tests of the `makeDocuments()` function for a grade!\n",
    "\n",
    "Follow the docstring for both functions below, and pay special attention to the data types. This function should replace all characters in the sentence that are not letters (upper or lower case ASCII letters), digits, or the percent sign % by a space. We'll then define \"words\" (which will be the *terms* for our index) to be any remaining alphanumeric characters which are found between spaces. For this assignment, do *not* normalize in any other way or stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77c2696a8021f2f6f7cea1f37b83a940",
     "grade": false,
     "grade_id": "q1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_tokenize(sentence):\n",
    "    '''Takes as input a line of text (assumed to be a multi-word sentence) and\n",
    "    returns that sentence, normalized and tokenized into words.\n",
    "    \n",
    "    Conventions:\n",
    "    -- upper and lower case ASCII letters (a-z and A-Z, with no diacritics) are kept\n",
    "    -- digits (0-9) are kept\n",
    "    -- percent sign (%) is kept\n",
    "    All other characters are converted to whitespace, and words (terms) are\n",
    "         then split on whitespace.\n",
    "    \n",
    "    args:\n",
    "        sentence (str): a sentence from the corpus, as a string\n",
    "    returns (normalized, tokenized):\n",
    "        normalized (str): a normalized version of the sentence, as described in the\n",
    "            conventions above\n",
    "        tokenized List[str]: the sequence of normalized words from the sentence, split\n",
    "            on whitespace, as a list\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    return (re.sub(r\"[^a-zA-Z0-9%]\",\" \",sentence),re.sub(r\"[^a-zA-Z0-9%]\",\" \",sentence).split())\n",
    "\n",
    "def makeDocuments(filepath):\n",
    "    '''reads in the source file and returns a structured list\n",
    "         of documents, **with text normalization** as described in\n",
    "         the normalize_tokenize() function.\n",
    "         (that is, you'll need to use that function from within this function)\n",
    "    \n",
    "    args:\n",
    "        filepath (str): path to train_orig.txt\n",
    "    returns:\n",
    "        documents (List[Tuple[int, str, Set]]): a list of triples:\n",
    "            publication source ID (as an integer)\n",
    "            document text (normalized but not split, as a string)\n",
    "            *set* of words in this document (normalized, as a set)\n",
    "\n",
    "       Document IDs within our collection are assumed to be the\n",
    "         integer index at which that document occurs in this list,\n",
    "         which should also match the line number in the original\n",
    "         document.\n",
    "'''\n",
    "    # YOUR CODE HERE\n",
    "    with open(filepath, \"r\") as file:\n",
    "        lines = [line.rstrip(\"\\n\") for line in file]\n",
    "\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        line2 = line[2:]\n",
    "        normalized, tokenized = normalize_tokenize(line2)\n",
    "        sentences.append((int(line[0]),normalized,set(tokenized)))\n",
    "    return sentences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ec53bb171a095f8248694d390e6f2e2",
     "grade": false,
     "grade_id": "cell-1fb609f870acc9a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll be testing (for points!) the document at index 4171. In the original file, that line looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e5bf855e10f2d71cd8d45a1a702f6a3",
     "grade": false,
     "grade_id": "cell-944fa043f8e67682",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sentence = 'hes the son of a physician from lawrence� he graduated from cooley�law school�worked for�his uncle the dentist who owned the el caribe catering hall in brooklyn dealt�in taxi medallions used to live in trump tower sought a city council seat and�paid money from trump�to former porn star stormy daniels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fc5f47e604dc4b48292439337b96066",
     "grade": false,
     "grade_id": "cell-77efc8bf850d1070",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the original file, this would have ended with a newline, but I'm assuming that you'll strip newlines in the part of your code that reads in the file, just like you did in HW1. So, your `normalize_tokenize()` function will be operating on it *after* the newline has been removed.\n",
    "\n",
    "I'm not sure where these non-ASCII characters came from, since they don't appear to be in the original article, which seems to be this one:\n",
    "\n",
    "https://web.archive.org/web/20220521092314/https://www.newsday.com/long-island/donald-trump-michael-cohen-w71594\n",
    "\n",
    "Your `normalize_tokenize()` function ought to reformat this document like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd7d6fe52d2c35beeb6503f703722b3a",
     "grade": false,
     "grade_id": "cell-88efa8f72a43fbe9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "normalized = 'hes the son of a physician from lawrence  he graduated from cooley law school worked for his uncle the dentist who owned the el caribe catering hall in brooklyn dealt in taxi medallions used to live in trump tower sought a city council seat and paid money from trump to former porn star stormy daniels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9b0dc202e637e056f2e106ab1088afb",
     "grade": false,
     "grade_id": "cell-9d9d70248ff07073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the characters that are NOT upper case ASCII A-Z, lower case ASCII a-z, digits 0-9, or the percent sign % are simply converted to a single space. In a few places, this results in a sequence of two or more spaces. We don't want to \"find\" a zero-length string in between two spaces, so be careful how you tokenize this with Python's `str.split()`!\n",
    "\n",
    "Your function should tokenize it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a8a7ff27803c14c6afae4fdf5a9c7db",
     "grade": false,
     "grade_id": "cell-464b3b91a4c2d440",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokenized = ['hes', 'the', 'son', 'of', 'a', 'physician', 'from', 'lawrence', 'he',\n",
    "             'graduated', 'from', 'cooley', 'law', 'school', 'worked', 'for', 'his',\n",
    "             'uncle', 'the', 'dentist', 'who', 'owned', 'the', 'el', 'caribe', 'catering',\n",
    "             'hall', 'in', 'brooklyn', 'dealt', 'in', 'taxi', 'medallions', 'used',\n",
    "             'to', 'live', 'in', 'trump', 'tower', 'sought', 'a', 'city', 'council',\n",
    "             'seat', 'and', 'paid', 'money', 'from', 'trump', 'to', 'former', 'porn',\n",
    "             'star', 'stormy', 'daniels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abcd1912545128e025a0bd87f9362e6b",
     "grade": false,
     "grade_id": "cell-92fa60bb204c72e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before the tests that count for points (below), here's a test just to make sure that this function is working properly. In LING 508, you'll learn about \"Test-Driven Development,\" but here's a chance to start working in this way. WRITE YOUR FUNCTION SO THAT IT WILL PASS THIS TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba49e69fb7390a7e1c4b3e8da0ba9497",
     "grade": false,
     "grade_id": "cell-3c4f46a03d5cf529",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray--your normalize_tokenize() function works as it should!\n"
     ]
    }
   ],
   "source": [
    "if (normalized, tokenized == normalize_tokenize(test_sentence)):\n",
    "    print(\"Hooray--your normalize_tokenize() function works as it should!\")\n",
    "else:\n",
    "    print(\"Hmm, keep trying!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff32fe37e4db3d08b3dcfb62518c3252",
     "grade": false,
     "grade_id": "cell-90142d649ed5585e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Now you can move on to the `makeDocuments()` function, and make sure it's working properly, as well&mdash;this time for points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6850e9dedee6acc3db575aee13abd791",
     "grade": true,
     "grade_id": "q1t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1a, 1 pt\n",
    "docs = makeDocuments(newbfile)\n",
    "assert len(docs) == 253781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e6c90da48fd0bb920aeb3e29b63a964",
     "grade": true,
     "grade_id": "q1t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1b, 1 pt\n",
    "assert type(docs[10]) == tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "053efbe92f504fe4cfa0abaa24dd9df0",
     "grade": true,
     "grade_id": "q1t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1c, 1 pt\n",
    "assert len(docs[10]) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "509130aa980826a70f3eb5c2e64816b5",
     "grade": true,
     "grade_id": "q1t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1d, 1 pt\n",
    "assert docs[4171][0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23ce893c7b040a138ec855c1b51fb14",
     "grade": true,
     "grade_id": "q1t5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1e, 1 pt\n",
    "#   This is really a test of your normalize_tokenize() function, and\n",
    "#   how you've integrated it into the makeDocuments() function.\n",
    "assert docs[4171][1] == 'hes the son of a physician from lawrence  he graduated from cooley law school worked for his uncle the dentist who owned the el caribe catering hall in brooklyn dealt in taxi medallions used to live in trump tower sought a city council seat and paid money from trump to former porn star stormy daniels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2262e5f5cd183229fa943af7b3e210f0",
     "grade": true,
     "grade_id": "q1t6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1f, 1 pt\n",
    "#   This is ALSO testing the output of your normalize_tokenize() function!\n",
    "assert len(docs[4171][2]) == 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfeeaef199d982e7a57dc88bfa057d8d",
     "grade": false,
     "grade_id": "q2q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.** The following function takes the output of `makeDocuments()` and creates an incidence-based index. We represent the index as a dictionary that maps from words to a *sorted* list of integer document IDs. The integer document IDs are the indices at which that document occurs in the structured list of documents that is returned by `makeDocuments()`. (4 points total)\n",
    "\n",
    "(Note that there is the potential for confusion here, since the word _index_ is being used two ways to refer to two different things. First, the incidence-based _index_ that we're building refers to a dictionary that maps from terms to a list of the document IDs that they occur in. Second, the integer document IDs are an _index_, that is, an integer that allows us to specify an item in our document list, like a subscript or a counter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48b060cc80f53fd68284cbefbb4a15aa",
     "grade": false,
     "grade_id": "q2a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def makeIndex(documents):\n",
    "    '''maps from a documents list to an\n",
    "    incidence index represented as a dictionary\n",
    "    from words to sorted lists of document IDs\n",
    "    \n",
    "    args:\n",
    "        documents (List[Tuple[int, str, Set]]):\n",
    "            a documents list as produced\n",
    "            by makeDocuments()\n",
    "    returns:\n",
    "        index Dict[str, List[int]]: \n",
    "            a dictionary from words to lists\n",
    "            of document IDs (ie, indices in the\n",
    "            documents list)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    index = {}\n",
    "    i = 0\n",
    "    for doc in documents:\n",
    "        for word in doc[2]:\n",
    "            if word in index:\n",
    "                index[word].append(i)\n",
    "            else:\n",
    "                index[word]=[i]\n",
    "        i+=1\n",
    "    return index\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1876082bad01e7b0941ec936127fefba",
     "grade": true,
     "grade_id": "q2t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "docs = makeDocuments(newbfile)\n",
    "idx = makeIndex(docs)\n",
    "\n",
    "# test 2a, 1 pt\n",
    "assert type(idx) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d2f866794e8c4134dd56b1f3c9aeff4",
     "grade": true,
     "grade_id": "q2t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 2b, 1 pt\n",
    "assert len(idx) == 61193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c77231b38409cb9afaf597950e79faf1",
     "grade": true,
     "grade_id": "q2t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 2c, 1 pt\n",
    "assert idx['champagnes'] == [223755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75a394574a92a5545acd32d13f03b519",
     "grade": true,
     "grade_id": "q2t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 2d, 1 pt\n",
    "assert idx['happiness'] == [16495,66139,84943,\n",
    "                            85998,91589,93472,\n",
    "                            120070,133078,193349]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59fe813c125fa302324beb7095aead5a",
     "grade": false,
     "grade_id": "q3q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.** Now write a function that will return the set of all document IDs that contain some set of words. (5 points total)\n",
    "\n",
    "The function should take two arguments:\n",
    "\n",
    "- an index (ie, the output of `makeIndex`)\n",
    "- a list of strings (ie, the search query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3001f72d8688283c2004c4ab509d15cb",
     "grade": false,
     "grade_id": "q3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def search(idx,ws):\n",
    "    '''returns the set of documents that contain\n",
    "    some set of words\n",
    "    \n",
    "    args:\n",
    "        idx Dict[str, List[int]]: \n",
    "            an incidence index, as created by\n",
    "            makeIndex()\n",
    "        ws List[str]:\n",
    "            a list of words (for use as a query)\n",
    "    returns:\n",
    "        docs Set[int]:\n",
    "            a set of document indices containing the words in ws\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    docs = set(idx[ws[0]])\n",
    "    for word in ws:\n",
    "        docs = docs&(set(idx[word]))\n",
    "    return set(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc70a5ece0ef6a070125ce531a42e8a7",
     "grade": true,
     "grade_id": "q3t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "docs = makeDocuments(newbfile)\n",
    "idx = makeIndex(docs)\n",
    "\n",
    "# test 3a, 1 pt\n",
    "assert type(search(idx,['airplane'])) == set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "868c88a540165600587cf3cc955f8fcb",
     "grade": true,
     "grade_id": "q3t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3b, 1 pt\n",
    "assert len(search(idx,['omelet'])) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb738cbef757e2874b5d4b858b574f30",
     "grade": true,
     "grade_id": "q3t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3c, 1 pt\n",
    "assert search(idx,['senate','reject']) == {68347, 144901, 177620, 181422, 181564}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba82e48abf6d84cdb3e45cac785f2664",
     "grade": true,
     "grade_id": "q3t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3d, 1 pt\n",
    "assert search(idx,['wow','congress','airplane']) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d9a3700c2c11f9e3d1460b83776dfe3",
     "grade": true,
     "grade_id": "q3t5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3e, 1 pt\n",
    "assert search(idx,['fire','wall']) == {32718, 46406, 49273, 67060, 154764, 178112, 201064}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97fb550acb6ec75309ac799c74331764",
     "grade": false,
     "grade_id": "q4q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**4.** Tweak the function so that it will complement any of the words. (5 points total)\n",
    "\n",
    "For example, if we call the function like this:\n",
    "\n",
    "```python\n",
    "dsearch(idx,['hat','*chair','coat'])\n",
    "```\n",
    "\n",
    "That will return all document IDs (indices) that contain *hat* and *coat*, but not *chair*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0b3d659f1f172fdf0dc9e3ba7105489",
     "grade": false,
     "grade_id": "q4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dsearch(idx,ws):\n",
    "    '''returns the set of documents that contain\n",
    "    or do *not* contain some set of words\n",
    "    \n",
    "    args:\n",
    "        idx Dict[str, List[int]]:\n",
    "            a term index as created by makeIndex()\n",
    "        ws List[str]:\n",
    "            a list of words any of which may be\n",
    "            marked with a prefixed '*', which\n",
    "            indicates complement/negation\n",
    "    returns:\n",
    "        docs Set[int]:\n",
    "            a set of document indices based on searching\n",
    "            for the words (possibly negated) in ws\n",
    "    '''\n",
    "    \n",
    "    # Start with all possible doc IDs\n",
    "    total_docs = max(doc for docs in idx.values() for doc in docs) + 1\n",
    "\n",
    "    all_docs = set(range(total_docs))\n",
    "    docs = None \n",
    "\n",
    "    for word in ws:\n",
    "        negate = word.startswith('*')\n",
    "        term = word[1:] if negate else word\n",
    "\n",
    "        term_docs = set(idx.get(term, []))\n",
    "\n",
    "        if docs is None:\n",
    "            docs = all_docs - term_docs if negate else term_docs\n",
    "        else:\n",
    "            if negate:\n",
    "                docs -= term_docs       \n",
    "            else:\n",
    "                docs &= term_docs       \n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62f62baed30316fa92fe90bc2b58bf08",
     "grade": true,
     "grade_id": "q4t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "docs = makeDocuments(newbfile)\n",
    "idx = makeIndex(docs)\n",
    "\n",
    "# test 4a, 1 pt\n",
    "assert type(dsearch(idx,['airplane'])) == set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e9dfb9975bed22fa76e58045959ec72",
     "grade": true,
     "grade_id": "q4t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4b, 1 pt\n",
    "assert len(dsearch(idx,['hats','*other'])) == 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3affc6bfa5643fe5fdd7a1fea0be62a",
     "grade": true,
     "grade_id": "q4t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4c, 1 pt\n",
    "assert len(dsearch(idx,['hats'])) + \\\n",
    "len(dsearch(idx,['*hats'])) == \\\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fbefe2bf8f7db88ad74fe785ec5e13e",
     "grade": true,
     "grade_id": "q4t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4d, 1 pt\n",
    "assert dsearch(idx,['win','send','*not']) == {57751, 251520}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38bb5c9a5e50e7a0241642a97ba6803",
     "grade": true,
     "grade_id": "q4t5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4e, 1 pt\n",
    "assert dsearch(idx,['win','*not']) == dsearch(idx,['*not','win'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a5642a2004c525042a16b366d042579",
     "grade": false,
     "grade_id": "q5q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**5.** How would you extend your function to include disjunction? In other words, think about what it would take to adapt this function so that you can have an OR connective as well as an AND connective. What aspects of this function will need to change? (3 points, manually graded)\n",
    "\n",
    "This has two parts. First, what would the syntax of the keywords need to be, that you would be passing as arguments to this function? How does the introduction of this new Boolean operation complicate the interpretation of a query?\n",
    "\n",
    "Second, how would you actually implement disjunction in the Python code? What is the built-in function that would be needed to represent it? *(Hint: Think about which operation we used to implement a Boolean AND. What's the operation that would correspond to Boolean OR?)*\n",
    "\n",
    "*For full points, your answer should make it clear that you understand how to represent the Boolean connectors in the search string in terms of set operations over the index. Your answer should also make it clear how the simple syntax that we've been using so far would become more complicated once we introduce the possibility of **disjunction** of search terms in addition to **conjunction** of search terms.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce8c30972f3f04e6dd70c587c6406518",
     "grade": true,
     "grade_id": "q5a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "So the first change that would happen is we would need to add a way to express whether a term was being \"anded\" in or \"ored\" in. Perhaps adding the & or | symbols in as strings in the arguments would work. After that what seems intuative to me is processing it in order of operations, processing ANDs before ORs. If you wanted to get really fancy you could maybe even add () as potential arguments to be grouping symbols that would give you more freedom as you expand the logic further. Using set theory vocabulary, we're aready doing intersections of sets and intersections of complements of sets, allowing or to be a keyword would just mean you need to add union of sets as well. The code for that part wouldn't be complicated, the built in set data structure supports the + symbol for union I think. I hope this explains it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
